{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84db7921-7974-4ee4-bf41-739dade3516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ebe40b-2c32-4ffd-99dd-0a0b915c6950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "df = df.sample(frac=1)\n",
    "df['gender'].replace([\"Male\", \"Female\"], [0, 1], inplace=True)\n",
    "df['disposition'].replace([\"Discharge\", \"Admit\"], [0,  1], inplace=True)\n",
    "df['esi'] = df['esi'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685f3da4-2b3a-4d7b-a6d5-28a751bacdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = dict(df['esi'].value_counts())\n",
    "class_weights = {x: min(df.shape[0]/class_weights[x], 10) for x in class_weights}\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9dc68c-3728-4543-8cdb-b385086aa68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_cols = [x for x in df.columns if x[:3] == \"cc_\"]\n",
    "med_cols = [x for x in df.columns if x[:5] == \"meds_\"]\n",
    "with open(\"pmh_cols.txt\") as f:\n",
    "    pmh_cols = f.readlines()\n",
    "pmh_cols = list(map(lambda x: x[:-1], pmh_cols))\n",
    "\n",
    "x_cols = [\"age\", \"gender\"] + cc_cols + pmh_cols\n",
    "y_cols = [\"disposition\"] + med_cols\n",
    "\n",
    "esi_data = pd.get_dummies(df['esi'], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc64945c-a84d-4204-ac96-d07f45be86d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_split = 0.9\n",
    "\n",
    "np_x_train = np.array(df[x_cols])[:int(val_split * df.shape[0]), :]\n",
    "np_esi_train = np.array(esi_data)[:int(val_split * df.shape[0]), :]\n",
    "np_y_train = np.array(df[y_cols])[:int(val_split * df.shape[0]), :]\n",
    "\n",
    "np_x_val = np.array(df[x_cols])[int(val_split * df.shape[0]):, :]\n",
    "np_esi_val = np.array(esi_data)[int(val_split * df.shape[0]):, :]\n",
    "np_y_val = np.array(df[y_cols])[int(val_split * df.shape[0]):, :]\n",
    "\n",
    "print(np_x_train.shape)\n",
    "print(np_esi_train.shape)\n",
    "print()\n",
    "print(np_x_val.shape)\n",
    "print(np_esi_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1dc2eb-9bb1-4628-98c6-b8ac06b74482",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(483),\n",
    "    tf.keras.layers.Dense(300, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(200, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(49, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "smooth = 1.\n",
    "def dice_coef(y_true, y_pred):\n",
    "    intersection = tf.keras.backend.sum(y_true * y_pred)\n",
    "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true) + tf.keras.backend.sum(y_pred) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "gen_model.compile(\n",
    "    loss=dice_coef_loss,\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        dice_coef,\n",
    "        tf.keras.metrics.AUC(curve=\"PR\"),\n",
    "        tf.keras.metrics.Precision(),\n",
    "        tf.keras.metrics.Recall()\n",
    "    ],\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c520a44-7b86-470c-aa55-ca5c80e5e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.01, decay_steps=5, decay_rate=0.99, staircase=True\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=1,\n",
    "    min_lr=0.0005\n",
    ")\n",
    "\n",
    "gen_model.fit(\n",
    "    x=np_x_train,\n",
    "    y=np_y_train,\n",
    "    epochs=30,\n",
    "    validation_data=(np_x_val, np_y_val),\n",
    "    batch_size=32,\n",
    "    callbacks=[reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f355bd8-4f5e-464e-818e-17e963a88417",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model.save(\"meds_admission.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c406a9-4c93-4bd4-b488-bccb94b9bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.01, decay_steps=5, decay_rate=0.99, staircase=True\n",
    ")\n",
    "\n",
    "esi_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(483),\n",
    "    tf.keras.layers.Dense(300, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(200, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(5, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "esi_model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540cafd8-8f8f-4640-bfee-35ff5dcad62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "esi_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a475c64-393f-46f3-82b9-bc7f7a1019ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=1,\n",
    "    min_lr=0.0005\n",
    ")\n",
    "\n",
    "esi_model.fit(\n",
    "    x=np_x_train,\n",
    "    y=np_esi_train,\n",
    "    epochs=30,\n",
    "    validation_data=(np_x_val, np_esi_val),\n",
    "    batch_size=32,\n",
    "    callbacks=[reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3cb224-db26-4832-9c22-202c95dcb11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "esi_model.save(\"65_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e6d0f6-1301-4291-a872-647de00aec43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
